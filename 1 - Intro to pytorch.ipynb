{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic steps of setting up a pytorch model\n",
    "Preprocessing of data is outside the scope of this tutorial. However, the input is expect to be some torch tensor type. Therefore there are some introductory tensor and torch Variable manipulations listed below.\n",
    "1. __Working with Torch tensors__ \n",
    "2. __Working with Torch Variables__ \n",
    "3. __Computing the gradients:__ using Torch Variables\n",
    "4. __Loss function and Optimizer:__ Logistic Regression example (Cross Entropy)\n",
    "5. __Data__: Using the pytorch dataloader class\n",
    "\n",
    "6. __Building a simple model__:\n",
    "  * __STEP 1 - Define model__\n",
    "  * __STEP 2 - Instantiate model__ \n",
    "  * __STEP 3 - Loss and optimiser __ \n",
    "  * __STEP 4 - Train __ using the given loss function and optimiser\n",
    "  * __STEP 5 - Predict__ use the trained network to make predictions on unseen input. Subsequently calculate the losses, accuracy, etc..\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Working with torch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random tensor as seed 0: \n",
      " 0.5488  0.5928\n",
      " 0.7152  0.8443\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n",
      "Different random tensor without seed 0: \n",
      " 0.6028  0.8579\n",
      " 0.5449  0.8473\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n",
      "Same tensor as the first one, because we use seed 0: \n",
      " 0.5488  0.5928\n",
      " 0.7152  0.8443\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# every seed produces the same random array\n",
    "torch.manual_seed(0)\n",
    "tensor_1 = torch.rand(2,2)\n",
    "\n",
    "tensor_2 = torch.rand(2,2)\n",
    "\n",
    "torch.manual_seed(0)\n",
    "tensor_3 = torch.rand(2,2)\n",
    "\n",
    "print('Random tensor as seed 0:', tensor_1)\n",
    "print('Different random tensor without seed 0:',tensor_2)\n",
    "print('Same tensor as the first one, because we use seed 0:',tensor_3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random tensor as seed 0: \n",
      " 0.6028  0.8579\n",
      " 0.5449  0.8473\n",
      "[torch.cuda.FloatTensor of size 2x2 (GPU 0)]\n",
      "\n",
      "Random tensor as seed 0: \n",
      " 0.4237  0.6236\n",
      " 0.6459  0.3844\n",
      "[torch.cuda.FloatTensor of size 2x2 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(0)\n",
    "    tensor_4 = torch.rand(2,2).cuda()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(0)\n",
    "    tensor_5 = torch.rand(2,2).cuda()\n",
    "    \n",
    "print('Random tensor as seed 0:', tensor_4)\n",
    "print('Random tensor as seed 0:', tensor_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.cuda.FloatTensor'>\n",
      "<class 'torch.FloatTensor'>\n"
     ]
    }
   ],
   "source": [
    "# Tensors on CPU vs GPU\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    tensor_1 = tensor_1.cuda()  # convert to gpu tensor with .cuda()\n",
    "\n",
    "print(type(tensor_1))\n",
    "\n",
    "tensor_1 = tensor_1.cpu()  # back to CPU with .cpu()\n",
    "print(type(tensor_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (re)size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2])\n",
      "\n",
      " 0.5488  0.5928\n",
      " 0.7152  0.8443\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n",
      "torch.Size([4])\n",
      "\n",
      " 0.5488\n",
      " 0.5928\n",
      " 0.7152\n",
      " 0.8443\n",
      "[torch.FloatTensor of size 4]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tensor_1.size())\n",
    "print(tensor_1)\n",
    "print(tensor_1.view(4).size())\n",
    "print(tensor_1.view(4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### inplace is faster due to memory efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.25 µs ± 42.8 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit tensor_4 - tensor_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.79 µs ± 72.8 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit tensor_4.sub(tensor_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3 µs ± 6.72 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit tensor_4.sub_(tensor_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### subtract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2])\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "print(tensor_1.size()) \n",
    "print(type(tensor_4)) # size works the same on cuda tensors\n",
    "print(tensor_4.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1.00000e+05 *\n",
      " -3.4531 -5.0686\n",
      " -5.2706 -3.1224\n",
      "[torch.cuda.FloatTensor of size 2x2 (GPU 0)]\n",
      "\n",
      "\n",
      " 0.9864  0.8904\n",
      " 1.6070  0.9010\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tensor_4.add(tensor_1.cuda())) # to add two tensor, they have to be the same type\n",
    "print(tensor_1.add(torch.rand(2,2).float())) # both GPU/CPU and float/long/double"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1.00000e+05 *\n",
      " -3.4531 -5.0686\n",
      " -5.2706 -3.1224\n",
      "[torch.cuda.FloatTensor of size 2x2 (GPU 0)]\n",
      "\n",
      "\n",
      "1.00000e+05 *\n",
      " -3.4531 -5.0686\n",
      " -5.2706 -3.1224\n",
      "[torch.cuda.FloatTensor of size 2x2 (GPU 0)]\n",
      "\n",
      "\n",
      "1.00000e+05 *\n",
      " -3.4531 -5.0686\n",
      " -5.2706 -3.1224\n",
      "[torch.cuda.FloatTensor of size 2x2 (GPU 0)]\n",
      "\n",
      "\n",
      "1.00000e+05 *\n",
      " -3.4531 -5.0686\n",
      " -5.2706 -3.1224\n",
      "[torch.cuda.FloatTensor of size 2x2 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tensor_4.sub(tensor_5))\n",
    "print(tensor_4)                 # sub subtracts tensor_4 with tensor_5 == tensor_4 - tensor_5\n",
    "print(tensor_4.sub_(tensor_5))\n",
    "print(tensor_4)                 # sub_ replaces tensor_4 with tensor_5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### multiply elementwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor_4: \n",
      "1.00000e+05 *\n",
      " -3.4531 -5.0686\n",
      " -5.2706 -3.1224\n",
      "[torch.cuda.FloatTensor of size 2x2 (GPU 0)]\n",
      "\n",
      "tensor_5: \n",
      " 0.4237  0.6236\n",
      " 0.6459  0.3844\n",
      "[torch.cuda.FloatTensor of size 2x2 (GPU 0)]\n",
      "\n",
      "Multiply elementwise: \n",
      "1.00000e+05 *\n",
      " -1.4629 -3.1606\n",
      " -3.4042 -1.2002\n",
      "[torch.cuda.FloatTensor of size 2x2 (GPU 0)]\n",
      "\n",
      "Multiply elementwise: \n",
      "1.00000e+05 *\n",
      " -1.4629 -3.1606\n",
      " -3.4042 -1.2002\n",
      "[torch.cuda.FloatTensor of size 2x2 (GPU 0)]\n",
      "\n",
      "Multiply inplace: \n",
      "1.00000e+05 *\n",
      " -1.4629 -3.1606\n",
      " -3.4042 -1.2002\n",
      "[torch.cuda.FloatTensor of size 2x2 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('tensor_4:',tensor_4)\n",
    "print('tensor_5:',tensor_5)\n",
    "# mul multiplies tensor_4 with tensor_5 == tensor_4 - tensor_5\n",
    "print('Multiply elementwise:',tensor_4.mul(tensor_5))    \n",
    "print('Multiply elementwise:',tensor_4 * tensor_5)\n",
    "    # mul_ without using additional memory \n",
    "print('Multiply inplace:',tensor_4.mul_(tensor_5))    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### division elementwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor_4: \n",
      "1.00000e+05 *\n",
      " -1.4629 -3.1606\n",
      " -3.4042 -1.2002\n",
      "[torch.cuda.FloatTensor of size 2x2 (GPU 0)]\n",
      "\n",
      "tensor_5: \n",
      " 0.4237  0.6236\n",
      " 0.6459  0.3844\n",
      "[torch.cuda.FloatTensor of size 2x2 (GPU 0)]\n",
      "\n",
      "Divide elementwise: \n",
      "1.00000e+05 *\n",
      " -3.4531 -5.0686\n",
      " -5.2706 -3.1224\n",
      "[torch.cuda.FloatTensor of size 2x2 (GPU 0)]\n",
      "\n",
      "Divide elementwise: \n",
      "1.00000e+05 *\n",
      " -3.4531 -5.0686\n",
      " -5.2706 -3.1224\n",
      "[torch.cuda.FloatTensor of size 2x2 (GPU 0)]\n",
      "\n",
      "Divide inplace: \n",
      "1.00000e+05 *\n",
      " -3.4531 -5.0686\n",
      " -5.2706 -3.1224\n",
      "[torch.cuda.FloatTensor of size 2x2 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('tensor_4:',tensor_4)\n",
    "print('tensor_5:',tensor_5)\n",
    "# mul multiplies tensor_4 with tensor_5 == tensor_4 - tensor_5\n",
    "print('Divide elementwise:',tensor_4.div(tensor_5))    \n",
    "print('Divide elementwise:',tensor_4 / tensor_5)\n",
    "    # mul_ without using additional memory \n",
    "print('Divide inplace:',tensor_4.div_(tensor_5))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: \n",
      "1.00000e+05 *\n",
      " -4.3618\n",
      " -4.0955\n",
      "[torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "\n",
      "std deviation: \n",
      "1.00000e+05 *\n",
      "  1.2852\n",
      "  1.3762\n",
      "[torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# mean\n",
    "print('mean:', tensor_4.mean(dim=0))\n",
    "\n",
    "# standard deviation\n",
    "print('std deviation:', tensor_4.std(dim=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Working with torch Variables\n",
    "* A variable wraps a Tensor, this enables accumulation of gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 1  1\n",
       " 1  1\n",
       "[torch.FloatTensor of size 2x2]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_a = Variable(torch.ones(2,2), requires_grad=True)\n",
    "var_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 2  2\n",
      " 2  2\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n",
      "Variable containing:\n",
      " 1  1\n",
      " 1  1\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "var_b = Variable(torch.ones(2,2), requires_grad=True)\n",
    "print(var_a + var_b)\n",
    "# same add, sub, mul, div operations can be applied \n",
    "print(torch.mul(var_a, var_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mul_ only supports scalar multiplication",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-bcc61c2ed5cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# But not in place! Why?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Because \"mul_ only supports scalar multiplication\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_a\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/scratch/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mmul_\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mMulConstant\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mul_ only supports scalar multiplication\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mul_ only supports scalar multiplication"
     ]
    }
   ],
   "source": [
    "# But not in place! Why?\n",
    "# Because \"mul_ only supports scalar multiplication\"\n",
    "print(var_a.mul_(var_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Gradients\n",
    "\n",
    "requires_grad enables calculation of gradients for Variables\n",
    "* Define original equation\n",
    "* Substitute equation with x\n",
    "* Reduce to scalar output using mean > o\n",
    "* Calculate gradients > o.backward()\n",
    "* Access the gradients using x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 1\n",
       " 1\n",
       "[torch.FloatTensor of size 2]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Variable(torch.ones(2), requires_grad=True)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 20\n",
       " 20\n",
       "[torch.FloatTensor of size 2]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = 5 * (x + 1) ** 2\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 20\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o = (1/2) * torch.sum(y)\n",
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# calculate the gradients for variables involved in o\n",
    "print(o.backward())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 10\n",
       " 10\n",
       "[torch.FloatTensor of size 2]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the gradients are stored in the Variable\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 10\n",
       " 10\n",
       "[torch.FloatTensor of size 2]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.backward(torch.FloatTensor([1.0,1.0]))\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 - Loss function and optimizer\n",
    "######  Logistic Regression example with Pytorch\n",
    "Bring together some of the previously introduced ideas in a simple application\n",
    " \n",
    "* **Linear function**:\n",
    "  * $y = A X + \\beta $\n",
    "  * with matrix $A$ the weights and $\\beta$ the bias \n",
    "    * dimensions of $A$: *output_dim x input_dim*\n",
    "    * dimensions of $\\beta$: *output_dim x 1*\n",
    "\n",
    "$g = \\frac{1}{1+e^{-y}} = \\frac{1}{1+e^{A X + \\beta}} \\to $ estimated probability that $y = 1$ given $x$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Optimising using Cross-entropy $D()$***\n",
    "\n",
    "$D(S,L) = L * log(S)-(1-L) *log(1-S)$\n",
    "* if $ L = 0 $ (for a specific label)\n",
    "  * $D(S,O) = -log(1-S)$\n",
    "    * $-log(1-S)$ : less positive if $S \\to 0$\n",
    "    * $-log(1-S)$ : more positive if $S \\to 1$ (bigger loss!)\n",
    "* if $ L = 1 $ (for a specific label)\n",
    "  * $D(S,1) = -log(S)$\n",
    "    * $-log(S)$ : less negative if $S \\to 1$\n",
    "    * $-log(S)$ : more negative if $S \\to 0$ (bigger loss!)\n",
    "    \n",
    "**Goal** is to minimise the cross entropy loss\n",
    "* $L = \\frac{1}{N}\\sum_i{D(g(Ax_i+b), L_i)}$\n",
    "  * minimise the overall distance D \n",
    "  * linear function $y \\to$ logistic function $S = g(y) \\to$ cross entropy function $D(S,L)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-log(1-S) with S near 0, very small:\n",
      " 9.999999722180686e-10\n",
      "-log(1-S) with S near 1, relatively big:\n",
      " 20.723265865228342\n",
      "log(S) with S near 1, very small:\n",
      " -9.999999722180686e-10\n",
      "log(S) with S near 0, relatively big:\n",
      " -20.72326583694641\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "print('-log(1-S) with S near 0, very small:\\n',-math.log(1-.000000001))\n",
    "print('-log(1-S) with S near 1, relatively big:\\n',-math.log(1-.999999999))\n",
    "\n",
    "print('log(S) with S near 1, very small:\\n',math.log(.999999999))\n",
    "print('log(S) with S near 0, relatively big:\\n',math.log(.000000001))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 -  Data using the pytorch dataloader class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# vision dataset imports\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dataset = dsets.MNIST(root='./dataset',\n",
    "                           train=True,\n",
    "                           transform=transforms.ToTensor(),\n",
    "                           download=False) # set to True to download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# image with 28 by 28 pixels\n",
    "train_dataset[0][0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label for the first image\n",
    "train_dataset[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 100\n",
    "n_iters = 3000\n",
    "\n",
    "num_epochs = int(n_iters / (len(train_dataset) / batch_size))\n",
    "num_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check iterability of trainingset\n",
    "import collections\n",
    "isinstance(train_loader, collections.Iterable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# no batch_size required really, otherwise same as train_loader without shuffle\n",
    "test_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6 - Buidling a simple model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP 1 - CREATE THE MODEL CLASS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activation functions:\n",
    "###### Sigmoid (logistic)\n",
    "* $\\sigma(x) = \\frac{1}{1+e^{-x}}$\n",
    "* Input number $\\to$ ouput between [0, 1]\n",
    "  * large negative number $\\to$ 0\n",
    "  * large positive number $\\to$ 1\n",
    "* Cons:\n",
    "  1. Activation saturates at 0 or 1 with __gradients ~ 0__\n",
    "    * No signal to update weights, __thus cannot learn__\n",
    "    * Solution: carefully initialise weights\n",
    "  2. Outputs not centered around 0\n",
    "    * outputs always positive $\\to$ gradients always pos or neg $\\to$ __bad for gradient updates__\n",
    "\n",
    "###### Tanh (a scaled sigmoid)\n",
    "* $tanh(x) = 2\\sigma(2x)-1$ \n",
    "* Input number $\\to$ ouput between [-1, 1]\n",
    "  * large negative number $\\to$ -1\n",
    "  * large positive number $\\to$ 1\n",
    "* Cons:\n",
    "  1. Activation saturates at 0 or 1 with __gradients ~ 0__\n",
    "    * No signal to update weights, __thus cannot learn__\n",
    "    * Solution: carefully initialise weights\n",
    "\n",
    "###### ReLU\n",
    "* $f(x) = max(0, x)$ \n",
    "* Pros:\n",
    "  1. Accelerate convergence, __thus train faster__\n",
    "  2. Computationally inexpensive w.r.t. sigmoid/tanh\n",
    "* Cons:\n",
    "  1. Many ReLU units end up with a 0 gradient\n",
    "    * Solution: carefully select (anneal) learning rate\n",
    "\n",
    "###### Swish\n",
    "* $f(x) = x * \\sigma(x)$\n",
    "* smooth, non-motonic functions that has similar performance to ReLU\n",
    "  * Consistently matches or outperforms ReLU on deep networks, for a variety of applications\n",
    "* Pros:\n",
    "  1. Accelerate convergence, __thus train faster__\n",
    "* Cons: \n",
    "  1. Computationally more expensive than ReLU\n",
    "  2. Again many units end up with a 0 gradient\n",
    "    * Solution: carefully select (anneal) learning rate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Network, self).__init__()\n",
    "        # linear layer\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        # non-linearity\n",
    "        self.activation = nn.Sigmoid()\n",
    "        # linear function \n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        # linear layer\n",
    "        self.activation = nn.Sigmoid()\n",
    "        # linear function \n",
    "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)             # Linear\n",
    "        x = self.activation(x)  # activation function\n",
    "        x = self.fc2(x)             # Linear\n",
    "        x = self.activation(x)  # activation function\n",
    "        x = self.fc3(x)             # Linear\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP 2 - INSTANTIATE THE MODEL CLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input dimensionality has to be the same as the image size!\n",
    "input_size = 28 * 28\n",
    "# hidden layer size set to 100\n",
    "hidden_size = 100\n",
    "# labels 0-9\n",
    "output_size = 10\n",
    "\n",
    "model = Network(input_size, hidden_size, output_size)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP 3 - LOSS AND OPTIMIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# how are you updating the parameters for every epoch?\n",
    "learning_rate = 0.1\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.parameters at 0x7fb956dfd5c8>\n",
      "6\n",
      "alpha:\n",
      " torch.Size([100, 784])\n",
      "beta:\n",
      " torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "# print the parameters \n",
    "print(model.parameters())\n",
    "print(len(list(model.parameters()))) # amount of layers\n",
    "\n",
    "# FC 1 parameters\n",
    "print('alpha:\\n',list(model.parameters())[0].size()) # linear layer parameters\n",
    "# FC 1 bias parameters\n",
    "print('beta:\\n',list(model.parameters())[1].size()) # output layer parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP 4 - TRAIN THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 784])\n"
     ]
    }
   ],
   "source": [
    "# print sizes of shizzle if the model doesn't like you\n",
    "for i, (images, labels) in enumerate(train_loader):\n",
    "    if i == 1:\n",
    "        print(images.view(-1,28*28).size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500 \t Loss 2.1819 \t Accuracy: 33.1833\n",
      "Iteration: 1000 \t Loss 1.1270 \t Accuracy: 67.1633\n",
      "Iteration: 1500 \t Loss 0.7555 \t Accuracy: 80.8650\n",
      "Iteration: 2000 \t Loss 0.4218 \t Accuracy: 85.2017\n",
      "Iteration: 2500 \t Loss 0.4461 \t Accuracy: 87.6033\n",
      "Iteration: 3000 \t Loss 0.3106 \t Accuracy: 88.9950\n"
     ]
    }
   ],
   "source": [
    "iter = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # convert input data to torch Variable\n",
    "        if torch.cuda.is_available():\n",
    "            # .cuda() has to be applied to the Tensor, not the Variable!\n",
    "            images = Variable(images.view(-1,28*28).cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "        else:\n",
    "            images = Variable(images.view(-1,28*28))\n",
    "            labels = Variable(labels)\n",
    "\n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward run to get outputs\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Calculate loss w.r.t labels (Softmax and CrossEntropy in a single step)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Compute gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        iter += 1\n",
    "        # compute the accuracy\n",
    "        if iter % 500 == 0:\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for images, labels in test_loader:\n",
    "                # Load images to a Torch Variable\n",
    "                if torch.cuda.is_available():\n",
    "                    images = Variable(images.view(-1,28*28).cuda())\n",
    "                else:\n",
    "                    images = Variable(images.view(-1,28*28))\n",
    "\n",
    "                # Forward pass to get outputs\n",
    "                outputs = model(images)\n",
    "\n",
    "                # Get predictions from the arg max                      \n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "\n",
    "                # Total correct predictions\n",
    "                if torch.cuda.is_available():\n",
    "                    correct += (predicted.cpu() == labels.cpu()).sum()\n",
    "                else:\n",
    "                    correct += (predicted == labels).sum()\n",
    "\n",
    "            accuracy = 100 * correct / total\n",
    "\n",
    "            print('Iteration: {} \\t Loss {:.4f} \\t Accuracy: {:.4f}'.format(iter, loss.data[0], accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP 5 - PREDICT LABELS FOR TEST SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# every prediction is a torch tensor holding \n",
    "# 10 likelihood values and the corresponding categories\n",
    "def get_category(prediction):\n",
    "    value, category = prediction.data.topk(1)\n",
    "    return category[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the likelihood of each class as a label\n",
    "if torch.cuda.is_available:\n",
    "    for batch, (images, _) in enumerate(test_loader):\n",
    "        # run model on a variable from the images.cuda(),convert the outcomes to cpu \n",
    "        predictions.append(model(Variable(images.view(-1,28*28).cuda())).cpu())\n",
    "else:\n",
    "    for batch, (images, _) in enumerate(test_loader):\n",
    "        predictions.append(Variable(images.view(-1, 28*28)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first prediction is a 5\n",
    "get_category(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n"
     ]
    }
   ],
   "source": [
    "# store the actual labels\n",
    "true_labels = []\n",
    "for batch, (_, labels) in enumerate(test_loader):\n",
    "    true_labels.append(labels.numpy())\n",
    "\n",
    "print(len(true_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_labels[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion = torch.zeros(10, 10)\n",
    "n_confusion = 60000\n",
    "\n",
    "for i in range(n_confusion):\n",
    "    label = true_labels[i][0]\n",
    "    prediction = get_category(predictions[i])\n",
    "    confusion[label][prediction] += 1\n",
    "\n",
    "\n",
    "# normalise the values\n",
    "for i in range(10):\n",
    "    confusion[i] = confusion[i]/confusion[i].sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAScAAAD7CAYAAAAo0VKhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ndFKKU0R00v8Hr3aGJAKEwCAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb95bc77a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "# Set up plot\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(confusion.numpy())\n",
    "fig.colorbar(cax)\n",
    "\n",
    "# Set up axes\n",
    "ax.set_xticklabels([''] + all_categories, rotation=90)\n",
    "ax.set_yticklabels([''] + all_categories)\n",
    "\n",
    "# Force label at every tick\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_model = True\n",
    "if save_model is True:\n",
    "    # save only parameters\n",
    "    torch.save(model.state_dict(), 'saved_shitty_test_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "load_model = True\n",
    "if load_model is True:\n",
    "    model.load_state_dict(torch.load('saved_shitty_test_model.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
